# Importa as bibliotecas necess√°rias
import streamlit as st  # Framework para cria√ß√£o de aplica√ß√µes web interativas
from openai import OpenAI  # Biblioteca para interagir com a API da OpenAI
from dotenv import load_dotenv  # Biblioteca para carregar vari√°veis de ambiente de um arquivo .env
import os  # Biblioteca para interagir com o sistema operacional

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# Obt√©m a chave de API da OpenAI a partir das vari√°veis de ambiente
openai_api_key = os.getenv("OPENAI_API_KEY")

# Verifica se a chave de API foi encontrada
if not openai_api_key:  # Caso a chave n√£o tenha sido configurada no arquivo .env
    st.error("Erro: A chave de API da OpenAI n√£o foi encontrada no arquivo .env.")
else:  # Caso a chave esteja dispon√≠vel

    # Define o t√≠tulo e a descri√ß√£o da aplica√ß√£o
    st.title("üí¨ Chatbot")  # Adiciona um t√≠tulo no topo da aplica√ß√£o
    st.write(
        "Chatbot simples implementado pelos alunos Celio Carcalto e Anahi Philbois que utiliza o modelo GPT-4o1-mini da OpenAI para gerar respostas estruturadas por guardrails predefinidos."
    )  # Adiciona um texto explicativo sobre o funcionamento do chatbot

    # Cria um cliente OpenAI utilizando a chave de API fornecida
    client = OpenAI(api_key=openai_api_key)

    # Inicializa a vari√°vel de estado da sess√£o para armazenar as mensagens do chat
    # Isso garante que as mensagens sejam preservadas mesmo ap√≥s recarregamentos
    if "messages" not in st.session_state:
        st.session_state.messages = []  # Lista para armazenar as mensagens trocadas no chat
        
        # Carrega o conte√∫do do arquivo "estrutura.txt" como a mensagem inicial
        try:
            with open("estrutura.txt", "r", encoding="utf-8") as f:
                estrutura_inicial = f.read()  # L√™ o conte√∫do do arquivo

                # Envia a estrutura inicial como a primeira mensagem do "usu√°rio"
                st.session_state.messages.append({"role": "user", "content": estrutura_inicial})

                # Gera a resposta inicial do modelo
                response = client.chat.completions.create(
                    model="o1-mini",  # Modelo a ser utilizado
                    messages=st.session_state.messages,
                    stream=False,
                )
                resposta_modelo = response.choices[0].message.content  # Acessa o atributo `content`

                # Adiciona a resposta do modelo como a primeira mensagem vis√≠vel
                st.session_state.messages.append({"role": "assistant", "content": resposta_modelo})

                # Remove a mensagem inicial do "usu√°rio" para que n√£o seja exibida
                st.session_state.messages.pop(0)
        except FileNotFoundError:
            st.error("Erro: O arquivo 'estrutura.txt' n√£o foi encontrado na raiz do projeto.")
            st.stop()  # Interrompe a execu√ß√£o se o arquivo n√£o for encontrado

    # Exibe as mensagens existentes no chat, come√ßando pela resposta inicial
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):  # Define o estilo da mensagem com base no remetente
            st.markdown(message["content"])  # Exibe o texto da mensagem no formato Markdown

    # Adiciona um campo de entrada para o usu√°rio digitar uma nova mensagem
    if prompt := st.chat_input("Digite sua mensagem:"):

        # Armazena e exibe a mensagem do usu√°rio
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # Gera uma resposta usando a API da OpenAI
        try:
            response = client.chat.completions.create(
                model="o1-mini",
                messages=st.session_state.messages,
                stream=False,
            )
            resposta_modelo = response.choices[0].message.content  # Acessa o atributo `content`
        except Exception as e:
            st.error(f"Erro ao gerar a resposta: {e}")
            st.stop()

        # Armazena e exibe a resposta do modelo
        st.session_state.messages.append({"role": "assistant", "content": resposta_modelo})
        with st.chat_message("assistant"):
            st.markdown(resposta_modelo)
