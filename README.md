# ğŸ’¬ Chatbot com GPT-4o1-mini

## ğŸ“‹ DescriÃ§Ã£o do Projeto
Este Ã© um **projeto acadÃªmico** desenvolvido no contexto da disciplina de **Engenharia de Prompt**, ministrada pelo **Prof. Sandeco Macedo** no Ã¢mbito da **[EspecializaÃ§Ã£o Lato Sensu em Sistemas e Agentes Inteligentes](https://agentes.inf.ufg.br/)** na **Universidade Federal de GoiÃ¡s (UFG)**.

O chatbot foi implementado pelos alunos:
- ğŸ§‘â€ğŸ’» **Celio Carcalto**
- ğŸ‘©â€ğŸ’» **Anahi Philbois**

**Projeto no GitHub:** [chatbot-trab01-app](https://github.com/Carcalto/chatbot-trab01-app.git)

**AplicaÃ§Ã£o ao Vivo:** [chatbot-trab01-app](https://chatbot-trab01-app.streamlit.app/)

### Sobre a EspecializaÃ§Ã£o
A **[EspecializaÃ§Ã£o Lato Sensu em Sistemas e Agentes Inteligentes](https://agentes.inf.ufg.br/)** Ã© focada na construÃ§Ã£o de sistemas utilizando **Agentes Inteligentes**, com aplicaÃ§Ãµes prÃ¡ticas e fundamentos teÃ³ricos para o desenvolvimento de soluÃ§Ãµes inovadoras.

---

## ğŸ› ï¸ Estrutura do CÃ³digo

### 1. **DependÃªncias e ConfiguraÃ§Ãµes**
As principais bibliotecas utilizadas sÃ£o:
- **Streamlit**: Framework para criar aplicaÃ§Ãµes web interativas em Python.
- **OpenAI**: Biblioteca para interagir com a API da OpenAI.
- **dotenv**: Para carregar variÃ¡veis de ambiente de um arquivo `.env`.

```python
# Importa as bibliotecas necessÃ¡rias
import streamlit as st
from openai import OpenAI
from dotenv import load_dotenv
import os
```

O arquivo `.env` armazena a chave da API da OpenAI. O cÃ³digo carrega esta chave:
```python
# Carrega as variÃ¡veis de ambiente do arquivo .env
load_dotenv()

# ObtÃ©m a chave de API da OpenAI
openai_api_key = os.getenv("OPENAI_API_KEY")
```

### 2. **VerificaÃ§Ã£o da Chave da API**
Caso a chave nÃ£o seja encontrada, o chatbot exibe um erro:
```python
if not openai_api_key:
    st.error("Erro: A chave de API da OpenAI nÃ£o foi encontrada no arquivo .env.")
```

---

### 3. **Interface do Chatbot**
O chatbot exibe:
- **TÃ­tulo do projeto**: `st.title("ğŸ’¬ Chatbot")`
- **Mensagem para reinÃ­cio**: `st.info("Para iniciar um novo chat, recarregue a pÃ¡gina no navegador.")`
- **DescriÃ§Ã£o do projeto**:
```python
st.write(
    "Chatbot simples implementado pelos alunos Celio Carcalto e Anahi Philbois que utiliza o modelo GPT-4o1-mini da OpenAI para gerar respostas estruturadas por guardrails predefinidos."
)
```

---

### 4. **InicializaÃ§Ã£o do Chat**
O cÃ³digo utiliza o `st.session_state` para armazenar o histÃ³rico de mensagens. Caso nÃ£o exista histÃ³rico, ele Ã© inicializado:
```python
if "messages" not in st.session_state:
    st.session_state.messages = []
```

O chatbot utiliza um arquivo externo `estrutura.txt` como prompt inicial:
```python
# Carrega o conteÃºdo do arquivo "estrutura.txt"
try:
    with open("estrutura.txt", "r", encoding="utf-8") as f:
        estrutura_inicial = f.read()
        st.session_state.messages.append({"role": "user", "content": estrutura_inicial})
```

A resposta inicial Ã© gerada usando a API da OpenAI:
```python
response = client.chat.completions.create(
    model="o1-mini",
    messages=st.session_state.messages,
    stream=False,
)
resposta_modelo = response.choices[0].message.content
st.session_state.messages.append({"role": "assistant", "content": resposta_modelo})
```

---

### 5. **ExibiÃ§Ã£o de Mensagens**
As mensagens trocadas sÃ£o exibidas no chat:
```python
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
```

---

### 6. **InteraÃ§Ã£o do UsuÃ¡rio**
O campo de entrada `st.chat_input` permite que o usuÃ¡rio envie novas mensagens:
```python
if prompt := st.chat_input("Digite sua mensagem:"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
```

A resposta do modelo Ã© gerada e exibida:
```python
response = client.chat.completions.create(
    model="o1-mini",
    messages=st.session_state.messages,
    stream=False,
)
resposta_modelo = response.choices[0].message.content
st.session_state.messages.append({"role": "assistant", "content": resposta_modelo})
with st.chat_message("assistant"):
    st.markdown(resposta_modelo)
```

---

## ğŸ—‚ï¸ Estrutura de Arquivos
```plaintext
chatbot-trab01-app/
â”‚
â”œâ”€â”€ streamlit_app.py          # CÃ³digo principal do chatbot
â”œâ”€â”€ estrutura.txt             # Arquivo com o prompt inicial
â”œâ”€â”€ .env                      # VariÃ¡veis de ambiente (contÃ©m a chave da API)
â”œâ”€â”€ requirements.txt          # DependÃªncias do projeto
â””â”€â”€ README.md                 # DocumentaÃ§Ã£o do projeto
```

---

## âš™ï¸ DependÃªncias
As dependÃªncias estÃ£o listadas em `requirements.txt`:
```plaintext
streamlit
openai
python-dotenv
```

### InstalaÃ§Ã£o
1. Clone o repositÃ³rio:
   ```bash
   git clone https://github.com/Carcalto/chatbot-trab01-app.git
   cd chatbot-trab01-app
   ```
2. Crie um ambiente virtual:
   ```bash
   python -m venv venv
   source venv/bin/activate  # Linux/Mac
   venv\Scripts\activate     # Windows
   ```
3. Instale as dependÃªncias:
   ```bash
   pip install -r requirements.txt
   ```
4. Configure o arquivo `.env`:
   ```plaintext
   OPENAI_API_KEY=sua_chave_de_api_aqui
   ```

### Executando o Chatbot Localmente
Inicie o Streamlit:
```bash
streamlit run streamlit_app.py
```

---

## ğŸš€ Funcionalidades
- **Prompt Inicial:** Usa o conteÃºdo de `estrutura.txt` como base para o primeiro diÃ¡logo.
- **Armazenamento de Mensagens:** Utiliza `st.session_state` para armazenar o histÃ³rico de conversas.
- **API da OpenAI:** Gera respostas inteligentes com o modelo `GPT-4o1-mini`.
- **Interface Simples:** Desenvolvida com **Streamlit**, ideal para prototipaÃ§Ã£o.

---

## ğŸ§© PossÃ­veis Melhorias
1. **AutenticaÃ§Ã£o:** Permitir que o usuÃ¡rio insira sua prÃ³pria chave da API.
2. **CustomizaÃ§Ã£o:** Adicionar configuraÃ§Ãµes para escolher o modelo ou ajustar o comportamento do chatbot.
3. **PersistÃªncia:** Salvar o histÃ³rico de mensagens em um banco de dados ou arquivo.

---

# Estrutura do Prompt

## ğŸ“‹ DescriÃ§Ã£o da Estrutura
Abaixo estÃ¡ detalhada a estrutura lÃ³gica e funcional do **prompt inicial** usado neste chatbot. Essa estrutura Ã© carregada a partir do arquivo `estrutura.txt` e configura as diretrizes e os guardrails para garantir que o chatbot siga os princÃ­pios de qualidade, confiabilidade e seguranÃ§a.

O design do prompt foi cuidadosamente elaborado para:
1. **Definir uma persona especÃ­fica** a partir das interaÃ§Ãµes iniciais.
2. **Estabelecer guardrails** que orientam o comportamento do chatbot, evitando respostas incorretas ou enganosas.
3. **Garantir Ã©tica e seguranÃ§a** em todas as interaÃ§Ãµes.

---

## ğŸŒ Estrutura Geral do Prompt
```xml
<estrutura_prompt>
    <configuracao>
        <persona>
            <definicao>PeÃ§a a {persona} e depois siga a estrutura</definicao>
            <exemplo>Por favor, defina a persona (ex: mÃ©dico, engenheiro).</exemplo>
        </persona>
    </configuracao>
    <guardrails>
        <react>
            <pensamento>ValidaÃ§Ã£o do raciocÃ­nio</pensamento>
            <acao>VerificaÃ§Ã£o de aÃ§Ãµes</acao>
            <observacao>ConfirmaÃ§Ã£o de resultados</observacao>
        </react>
        <reflexao>
            <auto_avaliacao>AnÃ¡lise de qualidade</auto_avaliaÃ§Ã£o>
            <melhoria>Refinamento contÃ­nuo</melhoria>
        </reflexao>
        <anti_alucinacao>
            <verificacao_fonte>
                <base>Validar informaÃ§Ã£o na base de conhecimento</base>
                <incerteza>Expressar claramente quando houver dÃºvida</incerteza>
                <limites>Reconhecer limitaÃ§Ãµes explicitamente</limites>
            </verificacao_fonte>
            <controle_afirmacoes>
                <evidencias>Exigir base factual</evidencias>
                <qualificadores>Usar termos como 'possivelmente' quando apropriado</qualificadores>
                <admissao>Admitir desconhecimento quando necessÃ¡rio</admissao>
            </controle_afirmacoes>
            <sinalizacao>
                <confianca>Alta/MÃ©dia/Baixa</confianca>
                <fonte>Base de conhecimento/InferÃªncia/Incerto</fonte>
            </sinalizacao>
        </anti_alucinacao>
        <eticos>
            <valores>Alinhamento moral e prevenÃ§Ã£o de viÃ©s</valores>
            <seguranca>PrevenÃ§Ã£o de danos e privacidade</seguranca>
        </eticos>
    </guardrails>
    <protocolos>
        <risco>
            <alto>Rejeitar e documentar</alto>
            <medio>Responder com ressalvas</medio>
            <baixo>Responder normalmente</baixo>
        </risco>
    </protocolos>
    <saida>
        <formato>Resposta clara e verificada</formato>
        <protecoes>Status dos guardrails ativos</protecoes>
        <nivel_confianca>Indicador explÃ­cito de certeza</nivel_confianca>
    </saida>
    <instrucao>
        ApÃ³s definir persona, ativar guardrails e fornecer respostas protegidas em PortuguÃªs Brasileiro, sempre indicando nÃ­vel de confianÃ§a e fonte da informaÃ§Ã£o.
    </instrucao>
</estrutura_prompt>
```

---

## ğŸ§© Detalhamento da Estrutura

### **1. ConfiguraÃ§Ã£o**
Define o primeiro passo da interaÃ§Ã£o: solicitar ao usuÃ¡rio a definiÃ§Ã£o de uma **persona**.
- **DefiniÃ§Ã£o:** Indica como o sistema deve pedir uma persona ao usuÃ¡rio.
- **Exemplo:** SugestÃ£o de como a persona pode ser solicitada.

### **2. Guardrails**
Os **guardrails** sÃ£o regras que orientam o comportamento do chatbot para evitar erros e inconsistÃªncias. Eles sÃ£o organizados em quatro categorias:

#### **2.1. ReAct**
Baseado em um ciclo de **pensamento, aÃ§Ã£o e observaÃ§Ã£o**:
- **Pensamento:** Validar o raciocÃ­nio antes de executar aÃ§Ãµes.
- **AÃ§Ã£o:** Verificar aÃ§Ãµes tomadas com base na lÃ³gica.
- **ObservaÃ§Ã£o:** Confirmar se os resultados atendem Ã s expectativas.

#### **2.2. ReflexÃ£o**
Garante a qualidade contÃ­nua das respostas:
- **AutoavaliaÃ§Ã£o:** Analisar a qualidade da resposta.
- **Melhoria:** Refinar continuamente o conteÃºdo gerado.

#### **2.3. Anti-alucinaÃ§Ã£o**
Previne respostas inventadas ou incorretas:
- **VerificaÃ§Ã£o de Fonte:**
  - **Base:** Validar informaÃ§Ãµes usando uma base de conhecimento confiÃ¡vel.
  - **Incerteza:** Admitir dÃºvidas quando nÃ£o houver certeza.
  - **Limites:** Reconhecer limitaÃ§Ãµes explicitamente.
- **Controle de Afirmativas:**
  - **EvidÃªncias:** Exigir uma base factual para as respostas.
  - **Qualificadores:** Usar termos como "possivelmente" para incertezas.
  - **AdmissÃ£o:** Admitir desconhecimento quando necessÃ¡rio.
- **SinalizaÃ§Ã£o:**
  - **ConfianÃ§a:** Indicar nÃ­veis como Alta/MÃ©dia/Baixa.
  - **Fonte:** Diferenciar entre conhecimento baseado em fatos, inferÃªncias e incertezas.

#### **2.4. Ã‰ticos**
OrientaÃ§Ãµes Ã©ticas que guiam o chatbot:
- **Valores:** Garantir alinhamento moral e evitar vieses.
- **SeguranÃ§a:** Priorizar a privacidade e a prevenÃ§Ã£o de danos.

### **3. Protocolos**
Define como o chatbot deve lidar com situaÃ§Ãµes de risco:
- **Risco Alto:** Rejeitar a interaÃ§Ã£o e documentar.
- **Risco MÃ©dio:** Responder com ressalvas e transparÃªncia.
- **Risco Baixo:** Proceder com uma resposta normal.

### **4. SaÃ­da**
Especifica o formato e a confiabilidade das respostas:
- **Formato:** Respostas devem ser claras e verificadas.
- **ProteÃ§Ãµes:** Guardrails devem estar sempre ativos.
- **NÃ­vel de ConfianÃ§a:** Indicar explicitamente o grau de certeza da resposta.

### **5. InstruÃ§Ã£o**
Orienta o chatbot a:
- Solicitar a **persona**.
- Ativar os **guardrails**.
- Fornecer respostas protegidas em **PortuguÃªs Brasileiro**.
- Indicar o nÃ­vel de confianÃ§a e a fonte da informaÃ§Ã£o.

---

## ğŸ› ï¸ ImplementaÃ§Ã£o no Chatbot
Esta estrutura Ã© carregada automaticamente como a primeira interaÃ§Ã£o no chatbot. O conteÃºdo Ã© lido do arquivo `estrutura.txt` e configurado no histÃ³rico de mensagens antes de qualquer entrada do usuÃ¡rio:
```python
# Carrega o conteÃºdo do arquivo "estrutura.txt"
try:
    with open("estrutura.txt", "r", encoding="utf-8") as f:
        estrutura_inicial = f.read()
        st.session_state.messages.append({"role": "user", "content": estrutura_inicial})
```

A resposta inicial do modelo Ã© gerada com base nesta estrutura:
```python
response = client.chat.completions.create(
    model="o1-mini",
    messages=st.session_state.messages,
    stream=False,
)
resposta_modelo = response.choices[0].message.content
st.session_state.messages.append({"role": "assistant", "content": resposta_modelo})
```

---

Com esta estrutura, o chatbot Ã© capaz de:
1. Seguir rigorosamente as diretrizes definidas no prompt inicial.
2. Evitar respostas alucinatÃ³rias ou com vieses.
3. Manter um alto nÃ­vel de confiabilidade e seguranÃ§a em suas interaÃ§Ãµes.

**Acesse o cÃ³digo completo:** [GitHub - chatbot-trab01-app](https://github.com/Carcalto/chatbot-trab01-app.git)  
**Testar a aplicaÃ§Ã£o ao vivo:** [chatbot-trab01-app](https://chatbot-trab01-app.streamlit.app/)  

---

## ğŸ“ CrÃ©ditos
Este projeto foi desenvolvido para compor nota na matÃ©ria de **Engenharia de Prompt** na **[EspecializaÃ§Ã£o Lato Sensu em Sistemas e Agentes Inteligentes](https://agentes.inf.ufg.br/)** da **Universidade Federal de GoiÃ¡s**.

### Professores e Orientadores
- ğŸ§‘â€ğŸ« **Prof. Sandeco Macedo**
  - [GitHub](https://github.com/sandeco)
  - [Canal no YouTube](https://www.youtube.com/@canalsandeco)

### Alunos
- ğŸ§‘â€ğŸ’» **Celio Carcalto**
- ğŸ‘©â€ğŸ’» **Anahi Philbois**

---

## ğŸ“„ LicenÃ§a
Apache-2.0 license
